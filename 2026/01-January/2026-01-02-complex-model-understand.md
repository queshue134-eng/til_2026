# 2026-01-02 TIL: The Most Complex Model We Actually Understand

## Category: Machine Learning / AI Interpretability

### Video Reference

[![YouTube](https://img.shields.io/badge/YouTube-Video-red?style=flat-square&logo=youtube)](https://www.youtube.com/watch?v=D8GOeCFFby4)

### Key Takeaways

This Welch Labs video explores the fascinating tension in AI: we've built incredibly powerful models, but **most of them are black boxes**. The video examines what it means to truly "understand" a model and highlights examples where we actually do.

---

## ğŸ§  The Interpretability Problem

### Why Understanding Matters

| Reason          | Description                                       |
| --------------- | ------------------------------------------------- |
| **Safety**      | Can't trust what we don't understand              |
| **Debugging**   | Finding failures requires understanding           |
| **Improvement** | Hard to improve black boxes systematically        |
| **Regulation**  | Laws increasingly require explainability          |
| **Science**     | Understanding models = understanding intelligence |

### The Complexity Spectrum

```
Simple & Understood          Complex & Black Box
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                â”‚
Linear    Decision   Random    Neural    LLMs
Regression  Trees    Forests   Networks  (GPT)
â”‚                                                â”‚
â””â”€ Fully interpretable       "We have no idea" â”€â”˜
```

---

## ğŸ” What Does "Understanding" Mean?

### Levels of Understanding

| Level            | Description         | Example                                 |
| ---------------- | ------------------- | --------------------------------------- |
| **Behavioral**   | What it does        | "It classifies cats"                    |
| **Mechanistic**  | How it does it      | "These neurons detect edges"            |
| **Mathematical** | Provable properties | "Guaranteed bounds"                     |
| **Causal**       | Why it works        | "This architecture succeeds because..." |

### Current State of AI

| Model Type        | Understanding Level               |
| ----------------- | --------------------------------- |
| Linear regression | Full mathematical understanding   |
| Decision trees    | Full mechanistic understanding    |
| Small neural nets | Partial mechanistic understanding |
| CNNs              | Some feature visualization        |
| Transformers/LLMs | Very limited understanding        |

---

## ğŸ¯ Models We Actually Understand

### 1. Linear Regression

The gold standard of interpretability:

- Each coefficient has clear meaning
- Mathematical guarantees exist
- Can prove optimality

### 2. Decision Trees

Fully transparent reasoning:

- Each split is a human-readable rule
- Path from input to output is explicit
- Easy to debug and modify

### 3. Toy Neural Networks

Small networks trained on simple tasks:

- Can visualize all weights
- Trace every computation
- Anthropic's work on "toy models of superposition"

### 4. Modular Arithmetic Networks

Networks trained on modular addition (a + b mod p):

- Researchers discovered they learn **Fourier transforms**
- Complete mechanistic understanding achieved
- Published work showing exact algorithm learned

---

## ğŸ”¬ Mechanistic Interpretability

A growing field trying to reverse-engineer neural networks:

### Key Techniques

| Technique                 | What It Reveals                     |
| ------------------------- | ----------------------------------- |
| **Feature visualization** | What patterns activate neurons      |
| **Activation patching**   | Which components matter for outputs |
| **Circuit analysis**      | How components work together        |
| **Probing**               | What information is encoded where   |

### Notable Discoveries

| Discovery        | Model        | Finding                          |
| ---------------- | ------------ | -------------------------------- |
| Induction heads  | Transformers | Copy patterns from context       |
| Modular addition | Small nets   | Fourier-based algorithm          |
| Curve detectors  | CNNs         | Neurons for specific curve types |
| Successor heads  | GPT-2        | Increment token sequences        |

---

## ğŸ“Š The Trade-off

### Accuracy vs Interpretability

```
                 â–² Accuracy
                 â”‚
    Neural Nets  â”‚     â—
                 â”‚   â—
    Ensembles    â”‚ â—
                 â”‚
    Trees        â”‚   â—
                 â”‚
    Linear       â”‚ â—
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Interpretability
```

### Breaking the Trade-off

Emerging approaches trying to get both:

- **Sparse autoencoders** â€” Find interpretable features in large models
- **Concept bottleneck models** â€” Force intermediate concepts
- **Chain-of-thought** â€” Make reasoning explicit
- **Constitutional AI** â€” Bake in understandable principles

---

## ğŸ’¡ Why This Matters for AI Safety

### The Alignment Problem

If we don't understand how a model works:

- We can't verify its goals align with ours
- We can't predict behavior in new situations
- We can't fix subtle misalignment

### Mechanistic Interpretability Hope

If we can fully understand:

- We can audit for deceptive behavior
- We can modify goals directly
- We can verify safety properties

---

## ğŸ”— Key Research Groups

| Organization         | Focus                                  |
| -------------------- | -------------------------------------- |
| **Anthropic**        | Mechanistic interpretability, circuits |
| **DeepMind**         | Interpretability, alignment            |
| **OpenAI**           | Superalignment, interpretability       |
| **Redwood Research** | Adversarial robustness                 |
| **EleutherAI**       | Open interpretability research         |

---

### Additional Resources

- [Anthropic's Transformer Circuits Thread](https://transformer-circuits.pub/)
- [Distill.pub](https://distill.pub/) â€” Visual ML explanations
- [Welch Labs](https://www.welchlabs.com/) â€” ML education
- [Original Video: The most complex model we actually understand](https://www.youtube.com/watch?v=D8GOeCFFby4)
